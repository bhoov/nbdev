# release

> Auto-generated tagged releases and release notes from GitHub issues
- order: 18

```{python}
#| default_exp release
```

## Overview

`nbdev.release` provides 3 commands that you can run from your shell to manage your changelog file and git releases:

- `nbdev_changelog`: creates a CHANGELOG.md file from closed and labeled GitHub issues
- `nbdev_release_git`: tags and creates a release in GitHub for the current version
- `nbdev_release_gh`: calls `nbdev_changelog`, lets you edit the result, then pushes to git and calls `nbdev_release_git`

It provides 3 futher commands for releasing packages on pypi or conda:

- `nbdev_pypi`: Create and upload a pypi installer
- `nbdev_conda`: Create and upload a conda installer
- `nbdev_release_both`: Create and upload both pypi and conda installers

Here's a brief demonstration of how to use the changelog and git release tools in `nbdev.release`. This demo first creates an issue using the [`gh`](https://cli.github.com/) command line tool, and then closes it using `git`; you can also use GitHub's web interface for both of these tasks. (Note that this functionality used to be in a project called `fastrelease`, so in the video the command line tools have different names, starting with `fastrelease_` instead of `nbdev_`).

[![](images/release.svg){width="900px"}](images/release.svg)

### Setup

You'll need to get a GitHub [personal access token](https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token) if you haven't already. To do so, [click here](https://github.com/settings/tokens/new) and enter "nbdev" in the "Note" section, and click the `repo` checkbox.

Then click "Generate Token" at the bottom of the screen, and copy the token (the long string of letters and numbers shown). You can easily do that by clicking the little clipboard icon next to the token.

<img alt="Copying your token" width="743" caption="Copying your token" src="images/token.png">

It’s easiest to save the token as an environment variable `GITHUB_TOKEN` that can be automatically accessed. We recommend you do this is by adding the following to the end of your `.bashrc` or `.zshrc` file:

```bash
export GITHUB_TOKEN=xxx
```

…and then replace the `xxx` with the token you just copied. It will automatically be avaialble whenever you start a new shell (but don’t forget to `source` that file or open a new shell after you change it.).

### Creating release notes

Now you're ready to create your release notes. These are created in a file called `CHANGELOG.md`. Here's an example of what it creates: [nbdev CHANGELOG](https://github.com/fastai/nbdev/blob/master/CHANGELOG.md).

All issues with the label **bug**, **enhancement**, or **breaking** that have been closed in your repo since your last release will be added to the top of this file. If you haven't made any releases before, then all issues with those labels will be included.

Therefore, before you create or update `CHANGELOG.md`, go to your GitHub issues page, remove `is:open` from the filter, and label any issues you want included with one of the labels above. When you've done that, you can create or update your release notes by running in your terminal:

    nbdev_changelog

The titles and bodies of each issue will be added. Open `CHANGELOG.md` in your editor and make any edits that you want, and then commit the file to your repo (remember to `git add` it!)

### Tagging a release

You should now tag a release. This will create a tag in GitHub with your current version number in `settings.ini`, and will then make it into a release, using your latest release notes as the description of the release:

    nbdev_release_git

After you run this, be sure to increment your version number in `settings.ini`. You can either edit it manually, or if you use nbdev it can be done for you by running:

    nbdev_bump_version

### Doing both (creating release notes, and tagging a release)

To complete both of the steps above, run:

```
nbdev_release_gh
```

See the screencast above for a demonstration of this.

## Python API

```{python}
#| export
from fastcore.all import *
from ghapi.core import *

from datetime import datetime
import shutil,subprocess

from nbdev.doclinks import *
```

```{python}
#| hide
from nbdev.showdoc import show_doc
```

```{python}
#| export
GH_HOST = "https://api.github.com"
```

```{python}
#| export
def _find_config(cfg_name="settings.ini"):
    cfg_path = Path().absolute()
    while cfg_path != cfg_path.parent and not (cfg_path/cfg_name).exists(): cfg_path = cfg_path.parent
    return Config(cfg_path, cfg_name)
```

```{python}
#| export
def _issue_txt(issue):
    res = '- {} ([#{}]({}))'.format(issue.title.strip(), issue.number, issue.html_url)
    if hasattr(issue, 'pull_request'): res += ', thanks to [@{}]({})'.format(issue.user.login, issue.user.html_url)
    res += '\n'
    if not issue.body: return res
    return res + f"  - {issue.body.strip()}\n"

def _issues_txt(iss, label):
    if not iss: return ''
    res = f"### {label}\n\n"
    return res + '\n'.join(map(_issue_txt, iss))

def _load_json(cfg, k):
    try: return json.loads(cfg[k])
    except json.JSONDecodeError as e: raise Exception(f"Key: `{k}` in .ini file is not a valid JSON string: {e}")
```

## Release -

```{python}
#| export
class Release:
    def __init__(self, owner=None, repo=None, token=None, **groups):
        "Create CHANGELOG.md from GitHub issues"
        self.cfg = _find_config()
        self.changefile = self.cfg.config_path/'CHANGELOG.md'
        if not groups:
            default_groups=dict(breaking="Breaking Changes", enhancement="New Features", bug="Bugs Squashed")
            groups=_load_json(self.cfg, 'label_groups') if 'label_groups' in self.cfg else default_groups
        os.chdir(self.cfg.config_path)
        owner,repo = owner or self.cfg.user, repo or self.cfg.repo
        token = ifnone(token, os.getenv('NBDEV_TOKEN',None))
        if not token and Path('token').exists(): token = Path('token').read_text().strip()
        token = ifnone(token, os.getenv('GITHUB_TOKEN',None))
        if not token: raise Exception('Failed to find token')
        self.gh = GhApi(owner, repo, token)
        self.groups = groups

    def _issues(self, label):
        return self.gh.issues.list_for_repo(state='closed', sort='created', filter='all', since=self.commit_date, labels=label)
    def _issue_groups(self): return parallel(self._issues, self.groups.keys(), progress=False)
```

To create a markdown changelog, first create a `Release` object, optionally passing a mapping from GitHub labels to markdown titles. Put your github token in a file named `token` at the root of your repo.  `Release` attempts to fetch values for arguments from the following locations if not supplied:

- **owner:** fetched from the field `user` in `settings.ini`.  This is the owner name of the repository on GitHub. For example for the repo `fastai/fastcore` the owner would be `fastai`.
- **repo:** fetched from the field `lib_name` in `settings.ini`.  This is the name of the repository on GitHub.  For example for the repo `fastai/fastcore` the owner would be `fastcore`.
- **token:** fetched from a file named `token` at the root of your repo.  Creating a token is discussed in [the setup](https://fastrelease.fast.ai/#Set-up) section.
- **groups:** (optional) fetched from the field `label_groups` in `settings.ini`, which is a JSON string.  This is a mapping from label names to titles in your release notes. If not specified, this defaults to:

```python
{"breaking": "Breaking Changes", "enhancement":"New Features", "bug":"Bugs Squashed"}
```

```{python}
#|export
@patch
def changelog(self:Release,
              debug=False): # Just print the latest changes, instead of updating file
    "Create the CHANGELOG.md file, or return the proposed text if `debug` is `True`"
    if not self.changefile.exists(): self.changefile.write_text("# Release notes\n\n<!-- do not remove -->\n")
    marker = '<!-- do not remove -->\n'
    try: self.commit_date = self.gh.repos.get_latest_release().published_at
    except HTTP404NotFoundError: self.commit_date = '2000-01-01T00:00:004Z'
    res = f"\n## {self.cfg.version}\n"
    issues = self._issue_groups()
    res += '\n'.join(_issues_txt(*o) for o in zip(issues, self.groups.values()))
    if debug: return res
    res = self.changefile.read_text().replace(marker, marker+res+"\n")
    shutil.copy(self.changefile, self.changefile.with_suffix(".bak"))
    self.changefile.write_text(res)
    run(f'git add {self.changefile}')
```

```{python}
#| eval: false
rel = Release()
# print(rel.changelog(debug=True))
```

```{python}
#|export
@patch
def release(self:Release):
    "Tag and create a release in GitHub for the current version"
    ver = self.cfg.version
    notes = self.latest_notes()
    self.gh.create_release(ver, branch=self.cfg.branch, body=notes)
    return ver
```

This uses the version information from your `settings.ini`.

```{python}
#|export
@patch
def latest_notes(self:Release):
    "Latest CHANGELOG entry"
    if not self.changefile.exists(): return ''
    its = re.split(r'^## ', self.changefile.read_text(), flags=re.MULTILINE)
    if not len(its)>0: return ''
    return '\n'.join(its[1].splitlines()[1:]).strip()
```

All relevant pull requests and issues are fetched from the GitHub API, and are categorized according to a user-supplied mapping from labels to markdown headings.

## CLI functions

```{python}
#| export
@call_parse
def changelog(
    debug:store_true=False,  # Print info to be added to CHANGELOG, instead of updating file
    repo:str=None,  # repo to use instead of `lib_name` from `settings.ini`
):
    "Create a CHANGELOG.md file from closed and labeled GitHub issues"
    res = Release(repo=repo).changelog(debug=debug)
    if debug: print(res)
```

```{python}
#| export
@call_parse
def release_git(
    token:str=None  # Optional GitHub token (otherwise `token` file is used)
):
    "Tag and create a release in GitHub for the current version"
    ver = Release(token=token).release()
    print(f"Released {ver}")
```

```{python}
#| export
@call_parse
def release_gh(
    token:str=None  # Optional GitHub token (otherwise `token` file is used)
):
    "Calls `nbdev_changelog`, lets you edit the result, then pushes to git and calls `nbdev_release_git`"
    cfg = _find_config()
    Release().changelog()
    subprocess.run([os.environ.get('EDITOR','nano'), cfg.config_path/'CHANGELOG.md'])
    if not input("Make release now? (y/n) ").lower().startswith('y'): sys.exit(1)
    run('git commit -am release')
    run('git push')
    ver = Release(token=token).release()
    print(f"Released {ver}")
```

## Publish Packages

```{python}
#| export
from fastcore.all import *
from nbdev.config import *
from nbdev.cli import *

import yaml,subprocess,glob,platform
from os import system
try: from packaging.version import parse
except ImportError: from pip._vendor.packaging.version import parse

_PYPI_URL = 'https://pypi.org/pypi/'
```

```{python}
#| export
def pypi_json(s):
    "Dictionary decoded JSON for PYPI path `s`"
    return urljson(f'{_PYPI_URL}{s}/json')
```

```{python}
#| export
def latest_pypi(name):
    "Latest version of `name` on pypi"
    return max(parse(r) for r,o in pypi_json(name)['releases'].items()
               if not parse(r).is_prerelease and not nested_idx(o, 0, 'yanked'))
```

```{python}
#| export
def pypi_details(name):
    "Version, URL, and SHA256 for `name` from pypi"
    ver = str(latest_pypi(name))
    pypi = pypi_json(f'{name}/{ver}')
    rel = [o for o in pypi['urls'] if o['packagetype']=='sdist'][0]
    return ver,rel['url'],rel['digests']['sha256']
```

```{python}
#| export
import shlex
from subprocess import Popen, PIPE, CalledProcessError

def _run(cmd):
    res = ""
    with Popen(shlex.split(cmd), stdout=PIPE, bufsize=1, text=True, encoding="utf-8") as p:
        for line in p.stdout:
            print(line, end='')
            res += line

    if p.returncode != 0: raise CalledProcessError(p.returncode, p.args)
    return res
```

```{python}
#| export
def conda_output_path(name, build='build'):
    "Output path for conda build"
    return run(f'conda {build} --output {name}').strip().replace('\\', '/')
```

```{python}
#| export
def _write_yaml(path, name, d1, d2):
    path = Path(path)
    p = path/name
    p.mkdir(exist_ok=True, parents=True)
    yaml.SafeDumper.ignore_aliases = lambda *args : True
    with (p/'meta.yaml').open('w', encoding="utf-8") as f:
        yaml.safe_dump(d1, f)
        yaml.safe_dump(d2, f)
```

```{python}
#| export
def _get_conda_meta():
    cfg = get_config()
    name,ver = cfg.lib_name,cfg.version
    url = cfg.doc_host or cfg.git_url

    doc_url = (cfg.doc_host + cfg.doc_baseurl) if (cfg.doc_host and cfg.doc_baseurl) else url
    dev_url = cfg.git_url if cfg.git_url else url

    hostreqs = ['packaging', f'python >={cfg.min_python}']
    reqs = hostreqs+[]
    if cfg.get('requirements'): reqs += cfg.requirements.split()
    if cfg.get('conda_requirements'): reqs += cfg.conda_requirements.split()

    pypi = pypi_json(f'{name}/{ver}')
    rel = [o for o in pypi['urls'] if o['packagetype']=='sdist'][0]

    # Work around conda build bug - 'package' and 'source' must be first
    d1 = {
        'package': {'name': name, 'version': ver},
        'source': {'url':rel['url'], 'sha256':rel['digests']['sha256']}
    }

    _dir = cfg.lib_path.parent
    readme = _dir/'README.md'
    descr = readme.read_text() if readme.exists() else ''
    d2 = {
        'build': {'number': '0', 'noarch': 'python',
                  'script': '{{ PYTHON }} -m pip install . -vv'},
        'requirements': {'host':hostreqs, 'run':reqs},
        'test': {'imports': [cfg.lib_path.name]},
        'about': {
            'license': 'Apache Software',
            'license_family': 'APACHE',
            'home': dev_url, 'doc_url': doc_url, 'dev_url': dev_url,
            'summary': cfg.get('description'),
            'description': descr
        },
        'extra': {'recipe-maintainers': [cfg.get('user')]}
    }
    return name,d1,d2
```

```{python}
#| export
def write_conda_meta(path='conda'):
    "Writes a `meta.yaml` file to the `conda` directory of the current directory"
    _write_yaml(path, *_get_conda_meta())
```

This function is used in the `conda_package` CLI command.

**NB**: you need to first of all upload your package to PyPi, before creating the conda package.

```{python}
#| export
@call_parse
def write_requirements(path:str=''):
    "Writes a `requirements.txt` file to `directory` based on settings.ini."
    cfg = get_config()
    d = Path(path) if path else cfg.config_path
    req = '\n'.join([cfg.get(k, '').replace(' ', '\n') for k in ['requirements', 'pip_requirements']])
    (d/'requirements.txt').mk_write(req)
```

This function can be used in situations where you need to generate a `requirements.txt` file for a project.

```{python}
#| export
CONDA_WARNING='Conda support for nbdev is deprecated and scheduled for removal in a future version.'

def anaconda_upload(name, loc=None, user=None, token=None, env_token=None):
    "Upload `name` to anaconda"
    warn(CONDA_WARNING)
    user = f'-u {user} ' if user else ''
    if env_token: token = os.getenv(env_token)
    token = f'-t {token} ' if token else ''
    if not loc: loc = conda_output_path(name)
    if not loc: raise Exception("Failed to find output")
    return _run(f'anaconda {token} upload {user} {loc} --skip-existing')
```

```{python}
from fastcore.xtras import globtastic
```

```{python}
#| export
@call_parse
def release_conda(
    path:str='conda', # Path where package will be created
    do_build:bool_arg=True,  # Run `conda build` step
    build_args:str='',  # Additional args (as str) to send to `conda build`
    skip_upload:store_true=False,  # Skip `anaconda upload` step
    mambabuild:store_true=False,  # Use `mambabuild` (requires `boa`)
    upload_user:str=None  # Optional user to upload package to
):
    "Create a `meta.yaml` file ready to be built into a package, and optionally build and upload it"
    warn(CONDA_WARNING)
    name = get_config().lib_name
    write_conda_meta(path)
    out = f"Done. Next steps:\n```\ncd {path}\n"""
    os.chdir(path)
    build = 'mambabuild' if mambabuild else 'build'
    if not do_build: return print(f"{out}conda {build} {name}")

    for f in globtastic('out', file_glob='*.tar.bz2'): os.remove(f)
    cmd = f"conda {build} --output-folder out --no-anaconda-upload {build_args} {name}"
    print(cmd)
    res = _run(cmd)
    outs = globtastic('out', file_glob='*.tar.bz2')
    assert len(outs)==1
    loc = outs[0]
    if skip_upload: return print(loc)
    if not upload_user: upload_user = get_config().conda_user
    if not upload_user: return print("`conda_user` not in settings.ini and no `upload_user` passed. Cannot upload")
    if 'anaconda upload' not in res: return print(f"{res}\n\nFailed. Check auto-upload not set in .condarc. Try `--do_build False`.")
    return anaconda_upload(name, loc)
```

```{python}
#| export
def chk_conda_rel(
    nm:str,  # Package name on pypi
    apkg:str=None,  # Anaconda Package (defaults to {nm})
    channel:str='fastai',  # Anaconda Channel
    force:store_true=False  # Always return github tag
):
    "Prints GitHub tag only if a newer release exists on Pypi compared to an Anaconda Repo."
    if not apkg: apkg=nm
    condavs = L(loads(run(f'mamba repoquery search {apkg} -c {channel} --json'))['result']['pkgs'])
    condatag = condavs.attrgot('version').map(parse)
    pypitag = latest_pypi(nm)
    if force or not condatag or pypitag > max(condatag): return f'{pypitag}'
```

To build and upload a conda package, cd to the root of your repo, and then:

    nbdev_conda_package

Or to do things more manually:

```
nbdev_conda_package --do_build false
cd conda
conda build --no-anaconda-upload --output-folder build {name}
anaconda upload build/noarch/{name}-{ver}-*.tar.bz2
```

Add `--debug` to the `conda build command` to debug any problems that occur. Note that the build step takes a few minutes. Add `-u {org_name}` to the `anaconda upload` command if you wish to upload to an organization, or pass `upload_user` to `nbdev_conda_package`.

**NB**: you need to first of all upload your package to PyPi, before creating the conda package.

```{python}
#|export
@call_parse
def release_pypi(
    repository:str="pypi" # Respository to upload to (defined in ~/.pypirc)
):
    "Create and upload Python package to PyPI"
    _dir = get_config().lib_path.parent
    system(f'cd {_dir}  && rm -rf dist build && python setup.py sdist bdist_wheel')
    system(f'twine upload --repository {repository} {_dir}/dist/*')
```

Use `--repository` flag to upload to [TestPypi](https://test.pypi.org/) (e.g. `nbdev_pypi --repository testpypi`) and custom/private repositories. 

The [~/.pypirc](https://packaging.python.org/en/latest/specifications/pypirc/) file can be updated to configure the additional repositories, see example below:

```toml
[distutils]
index-servers =
    pypi
    testpypi
    private-repository

[pypi]
username = __token__
password = <PyPI token>

[testpypi]
username = __token__
password = <TestPyPI token>

[private-repository]
repository = <private-repository URL>
username = <private-repository username>
password = <private-repository password>
```

Use `nbdev_pypi --repository private-repository` to upload to the private repository.

```{python}
#|export
@call_parse
def release_both(
    path:str='conda', # Path where package will be created
    do_build:bool_arg=True,  # Run `conda build` step
    build_args:str='',  # Additional args (as str) to send to `conda build`
    skip_upload:store_true=False,  # Skip `anaconda upload` step
    mambabuild:store_true=False,  # Use `mambabuild` (requires `boa`)
    upload_user:str=None,  # Optional user to upload package to
    repository:str="pypi" # Pypi respository to upload to (defined in ~/.pypirc)
):
    "Release both conda and PyPI packages"
    release_pypi.__wrapped__(repository)
    release_conda.__wrapped__(path, do_build=do_build, build_args=build_args, skip_upload=skip_upload, mambabuild=mambabuild, upload_user=upload_user)
    nbdev_bump_version.__wrapped__()
```

## Bump Version

```{python}
#|export
def bump_version(version, part=2, unbump=False):
    version = version.split('.')
    incr = -1 if unbump else 1
    version[part] = str(int(version[part]) + incr)
    for i in range(part+1, 3): version[i] = '0'
    return '.'.join(version)
```

```{python}
#|export
@call_parse
def nbdev_bump_version(
    part:int=2,  # Part of version to bump
    unbump:bool=False):  # Reduce version instead of increasing it
    "Increment version in settings.ini by one"
    cfg = get_config()
    print(f'Old version: {cfg.version}')
    cfg.d['version'] = bump_version(get_config().version, part, unbump=unbump)
    cfg.save()
    update_version()
    nbdev_export.__wrapped__()
    print(f'New version: {cfg.version}')
```

## Export -

```{python}
#| hide
import nbdev; nbdev.nbdev_export()
```

```{python}

```